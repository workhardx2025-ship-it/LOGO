# Настройка системы распознавания речи

Приложение поддерживает два режима распознавания речи:

## 1. OpenAI Whisper API (по умолчанию)

**Преимущества:**
- Высокое качество распознавания
- Быстрая обработка
- Не требует локальных ресурсов

**Недостатки:**
- Требует API ключ OpenAI
- Зависит от интернет-соединения
- Может взиматься плата за использование

**Настройка:**
```env
SPEECH_RECOGNITION_SYSTEM=openai
OPENAI_API_KEY=your_api_key_here
```

## 2. Локальный Whisper (Xenova/Transformers)

**Преимущества:**
- Работает полностью локально
- Не требует API ключ
- Не зависит от интернета
- Бесплатно

**Недостатки:**
- Первая загрузка модели может занять несколько минут
- Требует больше оперативной памяти (рекомендуется минимум 4GB RAM)
- Может работать медленнее на слабых компьютерах

**Настройка:**
```env
SPEECH_RECOGNITION_SYSTEM=local
```

## Переключение между системами

### Способ 1: Через файл .env

Откройте `server/.env` и измените значение:

```env
# Для OpenAI API
SPEECH_RECOGNITION_SYSTEM=openai

# Для локального Whisper
SPEECH_RECOGNITION_SYSTEM=local
```

После изменения перезапустите сервер.

### Способ 2: Через переменные окружения

При запуске сервера:

```bash
# Windows PowerShell
$env:SPEECH_RECOGNITION_SYSTEM="local"; node index.js

# Linux/Mac
SPEECH_RECOGNITION_SYSTEM=local node index.js
```

## Резервное переключение (Fallback)

Если локальный Whisper не работает, можно автоматически переключиться на OpenAI API:

```env
SPEECH_RECOGNITION_SYSTEM=local
FALLBACK_TO_OPENAI=true
OPENAI_API_KEY=your_api_key_here
```

В этом случае при ошибке локального распознавания система автоматически попробует использовать OpenAI API.

## Выбор модели Whisper (локальный режим)

В файле `server/services/whisperLocal.js` можно изменить модель:

```javascript
// Доступные модели (от меньшей к большей):
'Xenova/whisper-tiny'    // ~75MB, быстрая, но менее точная
'Xenova/whisper-base'    // ~150MB, хороший баланс
'Xenova/whisper-small'   // ~500MB, рекомендуемая (по умолчанию)
'Xenova/whisper-medium'  // ~1.5GB, более точная
'Xenova/whisper-large'   // ~3GB, самая точная, но медленная
```

## Требования для локального Whisper

- **RAM**: Минимум 4GB (рекомендуется 8GB+)
- **Диск**: ~1-3GB свободного места для модели
- **CPU**: Современный процессор (работает на CPU, GPU опционально)

## Первый запуск локального Whisper

При первом использовании локального Whisper:

1. Модель будет автоматически загружена из интернета
2. Это может занять 5-15 минут в зависимости от скорости интернета
3. Модель сохранится локально и больше не будет загружаться
4. В консоли вы увидите прогресс загрузки

## Устранение проблем

### Локальный Whisper не работает

1. Проверьте, что установлены все зависимости:
   ```bash
   cd server
   npm install
   ```

2. Проверьте доступную память (должно быть минимум 4GB свободной RAM)

3. Попробуйте использовать меньшую модель (whisper-tiny или whisper-base)

4. Включите fallback на OpenAI:
   ```env
   FALLBACK_TO_OPENAI=true
   ```

### OpenAI API не работает

1. Проверьте API ключ в `.env` файле
2. Убедитесь, что у вас есть кредиты на аккаунте OpenAI
3. Проверьте интернет-соединение
4. Переключитесь на локальный режим:
   ```env
   SPEECH_RECOGNITION_SYSTEM=local
   ```

## Производительность

**OpenAI API:**
- Скорость: ~1-3 секунды на запрос
- Качество: Очень высокое

**Локальный Whisper (whisper-small):**
- Скорость: ~3-10 секунд на запрос (зависит от CPU)
- Качество: Высокое
- На GPU: ~1-3 секунды

## Рекомендации

- **Для продакшена**: Используйте OpenAI API для лучшей производительности
- **Для разработки/тестирования**: Используйте локальный Whisper для экономии
- **Для офлайн работы**: Обязательно используйте локальный Whisper

